# Horalix View Backend Environment Configuration

# Application
APP_NAME=Horalix View
ENVIRONMENT=development
DEBUG=true

# Server
HOST=0.0.0.0
PORT=8000
WORKERS=4

# Security
# IMPORTANT: Generate a strong secret key for production using:
#   openssl rand -hex 32
# Never use the default value in production!
SECRET_KEY=your-secret-key-here-generate-with-openssl-rand-hex-32
ACCESS_TOKEN_EXPIRE_MINUTES=60
ALGORITHM=HS256

# Database
# Individual components (used by docker-compose)
DB_HOST=localhost
DB_PORT=5432
DB_USER=horalix
DB_PASSWORD=horalix
DB_NAME=horalix_view

# Complete Database URL (alternative to individual components)
# For production, use this format:
# DATABASE_URL=postgresql+asyncpg://user:password@host:port/database
DATABASE_URL=postgresql+asyncpg://horalix:horalix@localhost:5432/horalix_view

# Redis
# Individual components
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0

# Complete Redis URL (alternative to individual components)
REDIS_URL=redis://localhost:6379/0

# DICOM
DICOM_AE_TITLE=HORALIX_VIEW
DICOM_PORT=11112
DICOM_STORAGE_DIR=./storage/dicom

# AI Models
# Directory where model weights are stored
AI_MODELS_DIR=./models
# Device to run inference on: 'cuda' for GPU, 'cpu' for CPU, or 'cuda:0' for specific GPU
AI_DEVICE=cuda
# Batch size for inference (reduce if running out of memory)
AI_BATCH_SIZE=4
# Enable mixed precision (FP16) for faster inference on compatible GPUs
AI_MIXED_PRECISION=true
# Enable AI features (set to false to disable AI endpoints)
AI_ENABLED=true
# Confidence threshold for detection models
AI_CONFIDENCE_THRESHOLD=0.5
# Maximum concurrent inference jobs
AI_MAX_CONCURRENT_JOBS=2

# Compliance
COMPLIANCE_HIPAA_MODE=true
COMPLIANCE_AUDIT_LOGGING_ENABLED=true
COMPLIANCE_ENCRYPTION_AT_REST=true

# CORS
CORS_ORIGINS=["http://localhost:3000","http://localhost:5173"]
