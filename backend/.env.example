# Horalix View Backend Environment Configuration

# Application
APP_NAME=Horalix View
ENVIRONMENT=development
DEBUG=true
INIT_DEFAULT_USERS=true

# Server
HOST=0.0.0.0
PORT=8000
WORKERS=4

# Security
# IMPORTANT: Generate a strong secret key for production using:
#   openssl rand -hex 32
# Never use the default value in production!
SECRET_KEY=your-secret-key-here-generate-with-openssl-rand-hex-32
ACCESS_TOKEN_EXPIRE_MINUTES=60
ALGORITHM=HS256

# Database
# Individual components (used by docker-compose)
DB_HOST=localhost
DB_PORT=5432
DB_USER=horalix
DB_PASSWORD=horalix
DB_NAME=horalix_view

# Complete Database URL (alternative to individual components)
# For production, use this format:
# DATABASE_URL=postgresql+asyncpg://user:password@host:port/database
DATABASE_URL=postgresql+asyncpg://horalix:horalix@localhost:5432/horalix_view

# Redis
# Individual components
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0

# Complete Redis URL (alternative to individual components)
REDIS_URL=redis://localhost:6379/0

# DICOM
DICOM_AE_TITLE=HORALIX_VIEW
DICOM_PORT=11112
DICOM_STORAGE_DIR=./storage/dicom
DICOM_MAX_UPLOAD_SIZE_GB=10
ENABLE_DEMO_DATA=false

# AI Models
# Directory where model weights are stored
AI_MODELS_DIR=./models
# Directory where model outputs (masks, reports) are stored
AI_RESULTS_DIR=./results
# Load all available models on startup (GPU heavy)
AI_AUTO_LOAD_MODELS=false
# Device to run inference on: 'cuda' for GPU, 'cpu' for CPU, or 'cuda:0' for specific GPU
AI_DEVICE=cuda:0
# Batch size for inference (reduce if running out of memory)
AI_BATCH_SIZE=4
# Enable mixed precision (FP16) for faster inference on compatible GPUs
AI_MIXED_PRECISION=true
# Enable AI features (set to false to disable AI endpoints)
AI_ENABLED=true
# Confidence threshold for detection models
AI_CONFIDENCE_THRESHOLD=0.5
# Maximum concurrent inference jobs
AI_MAX_CONCURRENT_JOBS=2

# External AI model commands (optional)
# Use $INPUT_NPZ, $INPUT_JSON, $INPUT_DIR, $OUTPUT_JSON, $DEVICE, $WEIGHTS_PATH in commands
AI_EXTERNAL_TIMEOUT_SECONDS=900
AI_EXTERNAL_WORKDIR=
AI_ECHONET_MEASUREMENTS_CMD=python -m app.services.ai.external_runners.echonet_measurements
AI_GIGAPATH_CMD=python -m app.services.ai.external_runners.prov_gigapath
AI_HOVERNET_CMD=python -m app.services.ai.external_runners.hovernet
# Optional: Hugging Face token for Prov-GigaPath weights
HF_TOKEN=

# Compliance
COMPLIANCE_HIPAA_MODE=true
COMPLIANCE_AUDIT_LOGGING_ENABLED=true
COMPLIANCE_ENCRYPTION_AT_REST=true

# CORS
CORS_ORIGINS=["http://localhost:3000","http://localhost:5173"]
